{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80aee410-aadf-4d58-b7ef-129f8acaaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyPDF2\n",
    "#pip install python-pptx\n",
    "#pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9746c2-55d9-4d2d-b651-88072255591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "from PyPDF2 import PdfReader\n",
    "from pptx import Presentation\n",
    "from docx import Document\n",
    "person_tagger = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0fcdd7-62c7-4900-873d-5d99a327568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.docx .pptx .pdf\n",
    "def obtener_nombre_archivos(extension):\n",
    "    archivos = []\n",
    "    for archivo in os.listdir(\"./dataset\"):\n",
    "        if archivo.endswith(extension):\n",
    "            archivos.append(archivo)\n",
    "    return archivos\n",
    "\n",
    "def leer_pdf(ruta_archivo):\n",
    "    archivoLectura = open(ruta_archivo,'rb')\n",
    "    documento = PdfReader(archivoLectura)\n",
    "    texto_documento = \"\"\n",
    "\n",
    "    for pagina in documento.pages:\n",
    "        texto_documento += pagina.extract_text()\n",
    "\n",
    "    texto_limpio = re.sub(r'\\W+', ' ', texto_documento)\n",
    "    #texto_limpio = re.sub(r'\\s+', ' ', texto_limpio)\n",
    "    return texto_limpio\n",
    "\n",
    "def leer_pptx(filepath):\n",
    "    presentation = Presentation(filepath)\n",
    "    texto_documento = \"\"\n",
    "\n",
    "    # Recorrer todas las diapositivas\n",
    "    for slide in presentation.slides:\n",
    "        # Recorrer todos los elementos de texto en la diapositiva\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                for paragraph in shape.text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        texto_documento += run.text\n",
    "                        texto_documento += \" \"\n",
    "                        \n",
    "    texto_limpio = re.sub(r'\\W+', ' ', texto_documento)\n",
    "    texto_limpio = re.sub(r'\\s+', ' ', texto_limpio)\n",
    "    return texto_limpio\n",
    "\n",
    "def leer_docx(ruta_archivo):\n",
    "    doc = Document(ruta_archivo)\n",
    "    texto_documento = \"\"\n",
    "\n",
    "    # Recorrer todos los párrafos del documento\n",
    "    for paragraph in doc.paragraphs:\n",
    "        texto_documento += paragraph.text\n",
    "        texto_documento += \" \"\n",
    "\n",
    "    texto_limpio = re.sub(r'\\W+', ' ', texto_documento)\n",
    "    texto_limpio = re.sub(r'\\s+', ' ', texto_limpio)\n",
    "    return texto_limpio\n",
    "\n",
    "def leer_documentos(nombre_archivos):\n",
    "    archivos = []\n",
    "    for archivo in nombre_archivos:\n",
    "        if(archivo.endswith(\".pdf\")):\n",
    "            archivos.append(leer_pdf(\"./dataset/\" + archivo))\n",
    "        if(archivo.endswith(\".pptx\")):\n",
    "            archivos.append(leer_pptx(\"./dataset/\" + archivo))\n",
    "        if(archivo.endswith(\".docx\")):\n",
    "            archivos.append(leer_docx(\"./dataset/\" + archivo))\n",
    "    return archivos\n",
    "\n",
    "def leer_archivo_analizar(nombre_archivo):\n",
    "    if(nombre_archivo.endswith(\".pdf\")):\n",
    "            return leer_pdf(nombre_archivo)\n",
    "    if(nombre_archivo.endswith(\".pptx\")):\n",
    "            return leer_pptx(nombre_archivo)\n",
    "    if(nombre_archivo.endswith(\".docx\")):\n",
    "            return leer_docx(nombre_archivo)\n",
    "    if(nombre_archivo.startswith(\"https://\")):\n",
    "            return \"es web\"\n",
    "\n",
    "def obtener_nombre_archivo(ruta):\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    return nombre_archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13065889-f941-4b82-8f9a-cd40c2722ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución\n",
    "nombres_archivos_pdf = obtener_nombre_archivos(\".pdf\")\n",
    "nombres_archivos_docx = obtener_nombre_archivos(\".docx\")\n",
    "nombres_archivos_doc = obtener_nombre_archivos(\".doc\")\n",
    "nombres_archivos_pptx = obtener_nombre_archivos(\".pptx\")\n",
    "nombre_archivos = []\n",
    "nombre_archivos.extend(nombres_archivos_pdf)\n",
    "nombre_archivos.extend(nombres_archivos_docx)\n",
    "nombre_archivos.extend(nombres_archivos_doc)\n",
    "nombre_archivos.extend(nombres_archivos_pptx)\n",
    "corpus = leer_documentos(nombre_archivos)\n",
    "nombre_archivo_a_analizar = \"./documentoSospechoso.pdf\"\n",
    "documento_a_analizar = leer_archivo_analizar(nombre_archivo_a_analizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00bc872-d841-407c-a297-7f48ada986c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e94214e-ea20-4119-ba62-ae8c3c1afa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del Archivo Procesado: documentoSospechoso.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre del Archivo Procesado: \" + nombre_archivo_a_analizar[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30494bb3-093e-42c2-9773-d302b5a0907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Alumno Pedro', 'MISC')]\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "#AIEngineering - Custom Named Entity Recognition using Python\n",
    "entrenamiento = [\n",
    "    (\"Alumno Pedro picazo\",{\"entities\": [(0,6,\"IDENTIFICADOR\")]})\n",
    "]\n",
    "\n",
    "ner = person_tagger.get_pipe(\"ner\")\n",
    "\n",
    "for _, anotaciones in entrenamiento:\n",
    "    for ent in anotaciones.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "#disable_pipes = [pipe for pipe in person_tagger.pipe_names if pipe != 'ner']\n",
    "#with person_tagger.disable_pipes(*disable_pipes):\n",
    "optimizer = person_tagger.resume_training()\n",
    "    \n",
    "for iteration in range(5):\n",
    "       random.shuffle(entrenamiento)\n",
    "       losses = {}\n",
    "        \n",
    "       batches = minibatch(entrenamiento,size=compounding(3.8,4.0,1.001))\n",
    "       for batch in batches:\n",
    "            examples = []\n",
    "            for text, annotation in batch:\n",
    "                examples.append(Example.from_dict(person_tagger.make_doc(text), annotation))\n",
    "            person_tagger.update(examples, drop=0.5, losses=losses, sgd=optimizer)\n",
    "\n",
    "\n",
    "for texto, _ in entrenamiento:\n",
    "    documento = person_tagger(texto)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in documento.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d05dd4e-ee35-4f44-bc65-d7e57b0a2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibles nombres del Autor:\n",
      "Dr Alejandro Prince Ing Hern\n",
      " Gallazzi Pablo Gabriel\n"
     ]
    }
   ],
   "source": [
    "print(\"Posibles nombres del Autor:\")\n",
    "tokens = word_tokenize(documento_a_analizar)\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "tokens_documento = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "per_tagger = person_tagger(documento_a_analizar)\n",
    "\n",
    "def contains_word(text, word):\n",
    "    return word in text\n",
    "\n",
    "for autor in per_tagger.ents[0:12]:\n",
    "    token_aux = word_tokenize(autor.text)\n",
    "    if(autor.label_ == \"PER\" and len(token_aux) > 2):\n",
    "        if(contains_word(autor.text,\"Alumno\")):\n",
    "            index = autor.text.find(\"Alumno\")\n",
    "            nuevo_texto = autor.text[index:]\n",
    "            nuevo_texto = nuevo_texto.replace(\"Alumno\",\"\")\n",
    "            print(nuevo_texto)\n",
    "        else:\n",
    "            print(autor.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0376f9b6-83a4-4453-9d59-122ca8cc7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import fnmatch\n",
    "\n",
    "paginaWeb = requests.get('https://es.wikipedia.org/wiki/Revoluci%C3%B3n_Industrial').text\n",
    "soup = BeautifulSoup(paginaWeb,'html.parser')\n",
    "buscarContenido = soup.find('body')\n",
    "parrafos = buscarContenido.find_all('p')\n",
    "\n",
    "listaStr = list()\n",
    "for elemento in parrafos:\n",
    "    parrafosUrl = elemento.getText()\n",
    "    listaStr.append(parrafosUrl)\n",
    "    \n",
    "#print(listaStr)\n",
    "    \n",
    "filtro = fnmatch.filter(listaStr,'texto')\n",
    "\n",
    "if filtro != []:\n",
    "    strFiltro = str(filtro).strip(\"['']\")\n",
    "    print(strFiltro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc355981-0c25-4b9e-b03c-6ed6ced68cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento analizado: Economía de experiencia (1).pdf\n",
      "Porcentaje de potencial plagio: 100.00%\n",
      "Frase: ' M rketing en internet y nueva econom a Econom a de experiencia Profesores Dr. Alejandro Prince Ing.', Ubicación: 0)\n",
      "Frase: 'Qu 3 elementos hacen resurgir con fuerza la idea de una econom a de experiencia 2.', Ubicación: 3)\n",
      "Frase: 'Explique y grafique las dimensiones y campos de la experiencia.', Ubicación: 7)\n",
      "Frase: 'De 3 ejemplos distintos reales si conoce, o invente de experiencias con estimulaci n de los sentidos.', Ubicación: 11)\n",
      "Frase: 'Se trata de lograr lo mejor de ambas partes, masividad y personalizaci n. En un principio surgi la econom a de las commodities animales, minerales, vegetales etc... Cuando a esas commodities se las empez a usar como materia prima de productos, pasamos de una econom a agraria a una industrial.', Ubicación: 41)\n",
      "Frase: 'El ant doto para eso es la personalizaci n, y pasamos a una econom a de servicios y con el tiempo se volvi a producir el proceso de comoditizaci n. Si otra vez aplicamos un proceso de personalizaci n pasamos a la econom a de la experiencia.', Ubicación: 43)\n",
      " \n",
      "Documento analizado: Economía de experiencia.pdf\n",
      "Porcentaje de potencial plagio: 100.00%\n",
      "Frase: ' M rketing en internet y nueva econom a Econom a de experiencia Profesores Dr. Alejandro Prince Ing.', Ubicación: 0)\n",
      "Frase: 'Qu 3 elementos hacen resurgir con fuerza la idea de una econom a de experiencia 2.', Ubicación: 3)\n",
      "Frase: 'Explique y grafique las dimensiones y campos de la experiencia.', Ubicación: 7)\n",
      "Frase: 'De 3 ejemplos distintos reales si conoce, o invente de experiencias con estimulaci n de los sentidos.', Ubicación: 11)\n",
      "Frase: 'Se trata de lograr lo mejor de ambas partes, masividad y personalizaci n. En un principio surgi la econom a de las commodities animales, minerales, vegetales etc... Cuando a esas commodities se las empez a usar como materia prima de productos, pasamos de una econom a agraria a una industrial.', Ubicación: 41)\n",
      "Frase: 'El ant doto para eso es la personalizaci n, y pasamos a una econom a de servicios y con el tiempo se volvi a producir el proceso de comoditizaci n. Si otra vez aplicamos un proceso de personalizaci n pasamos a la econom a de la experiencia.', Ubicación: 43)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from difflib import SequenceMatcher\n",
    "import nltk\n",
    "\n",
    "def find_potential_plagiarized_sentences(documents, new_document):\n",
    "    model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "    sentences = nltk.sent_tokenize(new_document)\n",
    "    \n",
    "    # Embeddings de los documentos existentes\n",
    "    document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "    \n",
    "    # Embeddings de las frases del nuevo documento\n",
    "    new_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    \n",
    "    # Calcular la similitud de coseno entre los embeddings\n",
    "    cos_sim_scores = util.pytorch_cos_sim(new_embeddings, document_embeddings)\n",
    "    \n",
    "    potential_plagiarized_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        max_sim_score = max(cos_sim_scores[i])\n",
    "        if max_sim_score > 0.6:  # Ajusta el umbral según sea necesario\n",
    "            doc_index = cos_sim_scores[i].argmax().item()\n",
    "            plagiarism_percentage = max_sim_score * 100\n",
    "            potential_plagiarized_sentences.append((sentence, doc_index, i, plagiarism_percentage))\n",
    "    \n",
    "    return potential_plagiarized_sentences\n",
    "\n",
    "\n",
    "for index in range(len(corpus)):\n",
    "    similitud = SequenceMatcher(None, documento_a_analizar,corpus[index]).ratio() * 100\n",
    "    if(similitud > 20):\n",
    "        print(\"Documento analizado: \" + nombre_archivos[index])\n",
    "        print(f\"Porcentaje de potencial plagio: {similitud:.2f}%\")\n",
    "        potential_plagiarized_sentences = find_potential_plagiarized_sentences(corpus[index], documento_a_analizar)\n",
    "        for sentence, doc_index, sent_index, plagiarism_percentage in potential_plagiarized_sentences:\n",
    "            print(f\"Frase: '{sentence}', Ubicación: {sent_index})\")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6c44f3-80be-4cdc-ab69-1a615c4a26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35405192761605037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text= \"Hello Nigga\"\n",
    "similitud = SequenceMatcher(None, documento_a_analizar,text)\n",
    "print(similitud.ratio() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6997a50-3c3a-4546-ac5f-674280055d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temas principales: ['progresi n valor .', 'm rketing internet nueva', 'econom econom experiencia profesores']\n"
     ]
    }
   ],
   "source": [
    "#Esto no está bien\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def extraer_temas_principales(texto, n=2, num_temas=3):\n",
    "    # Tokenización de palabras y etiquetado gramatical\n",
    "    tokens = word_tokenize(texto)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Eliminar palabras vacías (stopwords) y palabras con etiquetas no relevantes\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    #relevant_tags = ['NN', 'NNS', 'NNP', 'NNPS']  # Sustantivos en singular y plural\n",
    "    tokens = [token.lower() for (token, tag) in tagged_tokens if token.lower() not in stop_words]\n",
    "    \"\"\"and tag in relevant_tags\"\"\"\n",
    "\n",
    "    # Lematización de palabras\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Generar n-gramas de tamaño variable\n",
    "    ngramas = list(ngrams(tokens, n))\n",
    "\n",
    "    # Calcular frecuencia de n-gramas\n",
    "    fdist = FreqDist(ngramas)\n",
    "\n",
    "    # Obtener los temas principales más frecuentes sin palabras repetidas\n",
    "    temas_principales = []\n",
    "    for tema, _ in fdist.most_common():\n",
    "        if all(word not in ' '.join(temas_principales) for word in tema):\n",
    "            temas_principales.append(' '.join(tema))\n",
    "            if len(temas_principales) == num_temas:\n",
    "                break\n",
    "\n",
    "    return temas_principales\n",
    "\n",
    "# Ejemplo de uso\n",
    "temas = extraer_temas_principales(documento_a_analizar, n=4, num_temas=3)\n",
    "print(\"Temas principales:\", temas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f998f7-481c-47dd-b78d-11be68787fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de plagio: 25.50%\n"
     ]
    }
   ],
   "source": [
    "def calculate_plagiarism_percentage(documents, new_document):\n",
    "    model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "    sentences = nltk.sent_tokenize(new_document)\n",
    "\n",
    "    # Embeddings de los documentos existentes\n",
    "    document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "    # Embeddings de las frases del nuevo documento\n",
    "    new_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Calcular la similitud de coseno entre los embeddings\n",
    "    cos_sim_scores = util.pytorch_cos_sim(new_embeddings, document_embeddings)\n",
    "\n",
    "    # Calcular el máximo puntaje de similitud para cada frase\n",
    "    max_sim_scores = cos_sim_scores.max(dim=1)[0]\n",
    "\n",
    "    # Calcular el promedio de los máximos puntajes de similitud\n",
    "    plagiarism_percentage = max_sim_scores.mean().item() * 100\n",
    "\n",
    "    return plagiarism_percentage\n",
    "\n",
    "documents = [\n",
    "    \"Estoy aqui para estorbar hehe. Este es el primer documento.\",\n",
    "    \"Estoy aqui para estorbar hehe. Este es el segundo documento.\",\n",
    "    \"Hello\"\n",
    "]\n",
    "new_document = \"Estoy aqui para estorbar hehe. Este es un nuevo documento que podría contener plagio del primer documento. Esto es relleno awebo. VAMOOO\"\n",
    "\n",
    "plagiarism_percentage = calculate_plagiarism_percentage(documents[2], new_document)\n",
    "print(f\"Porcentaje de plagio: {plagiarism_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f0a9af0-0db6-4650-9264-3cb78f5937d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' M rketing en internet y nueva econom a Econom a de experiencia Profesores Dr. Alejandro Prince Ing. Hern n Borr Ing. Maximiliano Bracho Alumno Gallazzi, Pablo Gabriel 143.370 2 Fecha de Presentaci n 10 04 2017 Cuestionario 1. Qu 3 elementos hacen resurgir con fuerza la idea de una econom a de experiencia 2. Defina y caracterice una experiencia. Diferencias con Producto y Servicio. 3. Explique y grafique las dimensiones y campos de la experiencia. 4. Describa impresiones y sus distintas dimensiones. 5. De 3 ejemplos distintos reales si conoce, o invente de experiencias con estimulaci n de los sentidos. 6. Qu es la personalizaci n masiva Explique la progresi n del valor. 7. Cu les son las ventajas para la empresa de la personalizaci n masiva 8. Describa los 4 tipos de personalizaci n masiva. 9. Qu aporta el ciberespacio al tema sacrificio del cliente Respuestas 1. Los tres elementos son El poder de la tecnolog a que act a como facilitador. La creciente intensidad de la competencia que hace que se tengan que diferenciar. La prosperidad, es decir, hoy en d a se busca menos rutina, m s sorpresas experiencias 2. Cuando hablamos del producto nos referimos a, por ejemplo, una taza, un caf , etc Si nos referimos a un servicio hablamos de un conjunto de actividades es decir algo customizado para el cliente, pero cuando hablamos de una experiencia nos referimos a algo m s, pagamos para disfrutar de una serie de eventos acondicionados para atraparnos y gozar de una manera distinta que solo comprar el producto o adquirir el servicio. De hecho se usan los productos y servicios como herramientas para lograr entretener a los clientes. 3. Dimensiones Grado de participaci n que puede ser pasiva el cliente es un observador o activa tiene como protagonista al cliente Conexi n cliente evento que puede ir desde la atenci n o absorci n hasta la inmersi n f sica o virtual. Estas dimensiones se cruzan generando los cuatro campos Entretenimiento La persona pasivamente absorbe lo que lo que ocurre a trav s de sus sentidos. Educaci n Alcanza con la atenci n por parte de la persona, pero requiere participaci n activa de la misma. Est tica El individuo se sumerge pero no participa. Escapismo M xima inmersi n y protagonismo absoluto. 4. Cuando nos referimos a impresiones, hablamos de lo que se lleva el cliente de la experiencia vivida, es decir, los recuerdos. Las dimensiones son Tiempo Tradicionales, contempor neas o futuristas. Espacio Donde se desarrollan En el hogar, en el trabajo, interiores, exteriores, etc Tecnolog a Vanguardia, artesanales, naturales o artificiales. Autenticidad Originales o imitaciones. Sofisticaci n Nivel de refinamiento o lujo. Escala Grandioso, sencillo o peque o. 5. Algunos ejemplo pueden ser Disney, Las Vegas, Starbucks, Restaurantes tem ticos, Juegos Mentales solojuegosmentales.com y as podemos mencionar muchos otros. 6. La personalizaci n masiva, se trata de atender a los clientes de una forma nica, combinando los imperativos vigentes de bajo costo y la individualizaci n que requiere el mercado. Se trata de lograr lo mejor de ambas partes, masividad y personalizaci n. En un principio surgi la econom a de las commodities animales, minerales, vegetales etc... Cuando a esas commodities se las empez a usar como materia prima de productos, pasamos de una econom a agraria a una industrial. El problema es que con el tiempo se di un proceso de comoditizaci n y el producto se convirti en commoditie . El ant doto para eso es la personalizaci n, y pasamos a una econom a de servicios y con el tiempo se volvi a producir el proceso de comoditizaci n. Si otra vez aplicamos un proceso de personalizaci n pasamos a la econom a de la experiencia. Cuanto m s personalizado se haga, m s alto es el precio al que se puede vender. A esto Joseph Pine lo llama la progresi n del valor. 7. Las ventajas para la empresa son varias, mejorar los precios, mayor ingreso por cliente, menor necesidad de hacer descuentos, m s retenci n, y adquisici n de clientes por un costo m s bajo. 8. Los cuatro tipos son Personalizaci n colaborativa o experiencia exploratoria La empresa interact a directamente con el cliente, el producto final surge del trabajo conjunto. Primero se modifica la representaci n y luego el producto. Personalizaci n adaptativa o experiencia real En esta no cambia ni el producto ni la representaci n, sino que a partir de varias opciones el cliente cambia alguna funcionalidad las opciones ya est n incluidas en la oferta . Personalizaci n cosm tica o experiencia gratificante Customizar la representaci n, el producto se siente como dise ado para uno. Personalizaci n transparente o experiencia elusiva El cliente ya recibe una oferta a medida y no se entera expl citamente del proceso de personalizaci n 9. El ciberespacio es un excelente medio para evaluar el nivel de sacrificio brecha entre lo que el cliente realmente quiere y lo que termina aceptando . Por ejemplo el email. Adem s potencia el marketing uno a uno y el aprendizaje cont nuo de las necesidades y gustos del cliente por parte de la empresa. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miPDF = leer_pdf(\"./documentoSospechoso.pdf\")\n",
    "miPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b3a3f-8481-404a-a4c5-bf4575922b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp] *",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
